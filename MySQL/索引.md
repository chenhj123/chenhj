索引的出现其实就是为了提高数据查询的效率，就像书的目录一样。

### 索引模型

1. Hash

   哈希表是一种以键 - 值（key-value）存储数据的结构，我们只要输入待查找的键即 key，就可以找到其对应的值即 Value。哈希的思路很简单，把值放在数组里，用一个哈希函数把 key 换算成一个确定的位置，然后把 value 放在数组的这个位置。哈希函数出现相同则会拉出链表来存放。

   因为拉出的链表不是有序的，所以哈希索引做区间查询会特别慢

   所以哈希结构适用于只有等值查询的场景

2. 有序数组

   等值查询和范围查询性能都挺优秀的，但是插入记录就要挪动后面所有记录，维护成本高

   所以这种适合于静态存储引擎

3. 二叉树

   二叉搜索树的特点是：父节点左子树所有结点的值小于父节点的值，右子树所有结点的值大于父节点的值。这样如果你要查 ID_card_n2 的话，按照图中的搜索顺序就是按照 UserA -> UserC -> UserF -> User2 这个路径得到。这个时间复杂度是 O(log(N))，并且维持这颗平衡二叉树，时间复杂度也是O(log(N))。

   二叉树搜索效率是最高的，实际上大多数的数据库存储不是二叉树，二十多叉树，因为索引不止存在内存中，还要写在磁盘上

   为什么数据库存储使用b+树 而不是二叉树，因为二叉树树高过高，每次查询都需要访问过多节点，即访问数据块过多，而从磁盘随机读取数据块过于耗时。

   以 InnoDB 的一个整数字段索引为例，这个 N 差不多是 1200。这棵树高是 4 的时候，就可以存 1200 的 3 次方个值，这已经 17 亿了。考虑到树根的数据块总是在内存中的，一个 10 亿行的表上一个整数字段的索引，查找一个值最多只需要访问 3 次磁盘。其实，树的第二层也有很大概率在内存中，那么访问磁盘的平均次数就更少了。

   MySql默认一个节点的长度为16K，一个整数（bigint）字段索引的长度为 8B,另外每个索引还跟着6B的指向其子树的指针；所以16K/14B ≈ 1170

   N 叉树由于在读写上的性能优点，以及适配磁盘的访问模式，已经被广泛应用在数据库引擎中了。

### InnoDB的索引模型

每一个索引都相当于一颗 B+ 树，一个表一定会有一个主键索引数

```sql
mysql> create table T(
id int primary key, 
k int not null, 
name varchar(16),
index (k))engine=InnoDB;
```

表中 R1~R5 的 (ID,k) 值分别为 (100,1)、(200,2)、(300,3)、(500,5) 和 (600,6)，两棵树的示例示意图如下

![InnoDB索引组织结构](E:\chenhj\images\InnoDB索引组织结构.png)

主键索引和普通索引有什么区别？

- 如果是where ID=500，则只需要搜索 ID 这棵 B+ 树
- 如果语句是 where k=5，则需要先搜索 k 索引树，得到 ID 的值，再主键索引一次，需要搜索两颗数，这个过程称为回表

### 索引维护

B+ 树为了维护索引的有序性，在插入新值的时候需要做必要的维护。以上图来看，如果插入新的行ID 值为 700，则只需要在 R5 的记录后面插入一个新纪录。如果新插入的 ID 值为 400， 就相对麻烦了，需要逻辑上挪动后面的数据，空出位置。

而更糟的情况是，如果 R5 所在的数据页已经满了，根据 B+ 树的算法，这时候需要申请一个新的数据页，然后挪动部分数据过去。这个过程称为页分裂。在这种情况下，性能自然会受影响。

除了性能外，页分裂操作还影响数据页的利用率。原本放在一个页的数据，现在分到两个页中，整体空间利用率降低大约 50%。

当然有分裂就有合并。当相邻两个页由于删除了数据，利用率很低之后，会将数据页做合并。合并的过程，可以认为是分裂过程的逆过程。

自增主键的插入数据模式，正符合了我们前面提到的递增插入的场景。每次插入一条新记录，都是追加操作，都不涉及到挪动其他记录，也不会触发叶子节点的分裂。

除了考虑性能外，我们还可以从存储空间的角度来看。假设你的表中确实有一个唯一字段，比如字符串类型的身份证号，那应该用身份证号做主键，还是用自增字段做主键呢？

由于每个非主键索引的叶子节点上都是主键的值。如果用身份证号做主键，那么每个二级索引的叶子节点占用约 20 个字节，而如果用整型做主键，则只要 4 个字节，如果是长整型（bigint）则是 8 个字节。

显然，主键长度越小，普通索引的叶子节点就越小，普通索引占用的空间也就越小。

那有没有场景需要业务字段作为主键的呢？还是有得，比如：1.我只有一个索引；2.该索引必须是唯一索引；这就是典型的 KV 场景。由于没有其他索引，所以也不用考虑索引叶子节点的问题。

## 实战操作

创建一个存储过程，模拟1000W条数据

```sql
//创建一个用户表
CREATE TABLE `tuser` (
  `id` int(11) NOT NULL,
  `id_card` varchar(32) DEFAULT NULL,
  `name` varchar(32) DEFAULT NULL,
  `age` int(11) DEFAULT NULL,
  `ismale` tinyint(1) DEFAULT NULL,
  PRIMARY KEY (`id`)
) ENGINE=InnoDB
```

id_card：身份证；name：名称；age：年龄；ismale：性别

### 覆盖索引

我们一般都是用身份证号去查询相关信息，正常在id_card上建立索引就可以了

如：SELECT * FROM tuser WHERE id_card='183167862091355167'

但如果我们有个高频的请求，根据身份证查询名称，那这个联合索引就很有意义了，它可以用到覆盖索引，不需要回表查整行记录

### 最左前缀原则

B+ 树这种索引结构，可以利用索引的 “最左前缀” ，来定位记录。

索引项是按照索引定义出现的字段顺序排列的

当你的逻辑需求是查到所有名字是 “张三” 的人时，可以快速定位到 ID4，然后向后遍历得到所有需要的结果

如果你要查询的是所有名字第一个字为 “张三”，SQL语句是 “where name like '张%' ”，也是可以满足条件的

可以看到，不只是索引的全部定义，只要满足最左前缀，就可以利用索引来加速检索。这个最左前缀可以是联合索引的最左 N 个字段，也可以是字符串索引的最左 M 个字符。

问题：如何对索引字段的排序？

第一原则，如果通过调整顺序，可以少维护一个索引，那么这个顺序往往就是需要有限考虑采用的

上面实践例子中，有了（身份证，姓名）索引，就不需要再单独建立（身份证索引）

### 索引下推

已上面为例子，如果存在索引（name，age）为例。检索出表中，名字第一个字是张，而且年龄是10岁的所有男孩。

如：select * from tuser where name like '张%' and age=10 and ismale=1;

在 MySQL 5.6 之前，只能从 ID3 开始一个个回表。到主键索引上找出数据行，再对比字段值。

而 MySQL 5.6 引入的索引下推优化（index condition pushdown)， 可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。

### 普通索引和唯一索引

首先我们想到，普通索引和唯一索引，在查询数据的时候，只不过多了一次判断是否唯一的操作，这对性能来讲是微乎其微，那为什么我要来讲这一个呢？

我先提一个概念，InnoDB 的数据是按数据页为单位来读写的。也就是说，当需要读一条记录的时候，并不是只读取当前的记录，而是会以页为单位，将其整体读入内存。在 InnoDB 中，每个数据页的大小默认是 16KB。

```sql
// id=1561156
SELECT * FROM tuser WHERE id_card='111267225757110521' 
// id=1561112
SELECT * FROM tuser WHERE id_card='589320518675346165' 

//id=6548974
SELECT * FROM tuser WHERE id_card='589320518675346165' 

// 提问：id_card 如果不加 '' 会发生什么事
```



我们再提一个概念，change buffer，当需要更新一个数据页时，如果数据页在内存中就直接更新，而如果这个数据页还没有在内存中的话，在不影响数据一致性的前提下，InnoDB 会将这些更新操作缓存在 change buffer 中，这样就不需要从磁盘中读入这个数据页了。在下次查询需要访问这个数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个页有关的操作。通过这种方式就能保证这个数据逻辑的正确性。

需要说明的是，虽然名字叫作 change buffer，实际上它是可以持久化的数据。也就是说，change buffer 在内存中有拷贝，也会被写入到磁盘上。

将 change buffer 中的操作应用到原数据页，得到最新结果的过程称为 merge。除了访问这个数据页会触发 merge 外，系统有后台线程会定期 merge。在数据库正常关闭（shutdown）的过程中，也会执行 merge 操作。

merge 的执行流程是这样的：

1. 从磁盘读入数据页到内存（老版本的数据页）；
2. 从 change buffer 里找出这个数据页的 change buffer 记录（可能有多个），依次应用，得到新版数据页；
3. 写 redo log 。这个 redo log 包含了数据的变更和 change buffer 的变更。

如果能将更新操作先记录在 change buffer，减少读磁盘，语句的执行速度会得到明显的提升。而且，数据读入内存是需要占用 buffer pool 的，所以这种方式能够避免占用内存，提高内存利用率。

对于唯一索引来说，所有更新操作都要判断这个操作是否违反唯一性约束。比如我们要插入一条记录，首先要判断数据是否唯一性，就需要把数据读入内存才能判断。如果都已经读入内存了，就直接更新内存就好了，这样会显得更快，就没必要用 change buffer 了。

因此，唯一索引的更新就不能使用 change buffer ，实际上也只有普通索引可以使用。

change buffer 用的是 buffer pool 里的内存，因此不能无限增大。change buffer 的大小，可以通过参数 innode_change_buffer_max_size 来动态设置，这个参数是按百分比来计算的。

我们再一起来看看如果要在这张表中插入一个新记录

1. 这个记录要更新的目标页在内存中

   - 对于唯一索引来说，找到 3 和 5 之间的位置，判断到没有冲突，插入这个值，语句执行结束；

   - 对于普通索引来说，找到 3 和 5 之间的位置，插入这个值，语句执行结束。

   普通索引和唯一索引对更新语句性能影响的差别，只是一个判断，只会耗费微小的 CPU 时间。但，这不是我们关注的重点。

   

2. 这个记录要更新的目标页不在内存中。

   - 对于唯一索引来说，需要将数据页读入内存，判断到没有冲突，插入这个值，语句执行结束；
   - 对于普通索引来说，则是将更新记录在 change buffer，语句执行就结束了。

   将数据从磁盘读入内存涉及随机 IO 的访问，是数据库里面成本最高的操作之一。change buffer 因为减少了随机磁盘访问，所以对更新性能的提升是会很明显的。

使用场景

出现写多读少的业务，一般这种就是账单类、日志类系统

如果写入之后马上会查询，就会立即触发 merge 过程，这样随机访问 IO 次数不会减少，还需要付出 change buffer 维护时间。

那又有一个问题：redo log 和 change buffer 区别？

redo log 主要节省的是随机写磁盘的 IO 消耗（转成顺序写），而 change buffer 主要节省的则是随机读磁盘的 IO 消耗。
